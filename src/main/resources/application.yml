server:
  ssl:
    enabled: false
  port: 8443
  error:
    include-message: always
  reactive:
    session:
      timeout: 30d
      cookie:
        name: SESSION
        secure: false
        max-age: 30d
        http-only: true
        same-site: lax
  forward-headers-strategy: framework
spring:
  ai:
    chat:
      observations:
        log-prompt: false
        log-completion: false
        include-error-logging: true
    ollama:
      chat:
        options:
          model: llama3.2:1b
          max-tokens: 1000
          temperature: 0.2
      base-url: http://localhost:7869
      embedding:
        model: text-embedding-3-small
    openai:
      api-key: ${SPRING_AI_OPENAI_API_KEY}
      chat:
        options:
          model: gpt-4o-mini
          max-tokens: 1000
          temperature: 0.2
      embedding:
        options:
          model: text-embedding-3-small
          dimensions: 1536 #or 3072 for text-embedding-3-large
  data:
    mongodb:
      uri: ${SPRING_DATA_MONGODB_URI}
      auto-index-creation: true
  cloud:
    gateway:
      server:
        webflux:
          routes:
            - id: workley-gateway
              uri: http://localhost:8443
              predicates:
                - Path=/api/command/**
                - Path=/api/chats/**
  rsocket:
    server:
      transport: websocket
      mapping-path: /rsocket
  application:
    name: workley-gateway
gateway:
  security:
    anonymous:
      jwt:
        secret: ${GATEWAY_SECURITY_ANONYMOUS_JWT_SECRET}
management:
  health:
    rabbit:
      enabled: false
  endpoint:
    health:
      show-details: always
  endpoints:
    web:
      exposure:
        include: health, metrics
  metrics:
    tags:
      application: workley-gateway

